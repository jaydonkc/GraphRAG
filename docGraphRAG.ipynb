{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "879bab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a1ba4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b6137c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaydonkc/shared/vscode/ai-projects/PSC-CMU-Pitt-Hackathon/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any, Optional, Set\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45527f67",
   "metadata": {},
   "source": [
    "vLLM Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85cbbef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class ReasoningStep(BaseModel):\n",
    "    step: str = Field(..., description=\"A reasoning step in the planning process\")\n",
    "    required_info: List[str] = Field(..., description=\"Types of information needed for this step\")\n",
    "\n",
    "class QueryPlan(BaseModel):\n",
    "    reasoning_steps: List[ReasoningStep] = Field(..., description=\"Step-by-step plan to answer the query\")\n",
    "    key_concepts: List[str] = Field(..., description=\"Key concepts that need to be found in the knowledge graph\")\n",
    "    search_strategy: str = Field(..., description=\"Strategy for searching the knowledge graph\")\n",
    "    expected_answer_type: str = Field(..., description=\"What type of answer is expected (causal, descriptive, comparative, etc.)\")\n",
    "\n",
    "class NotebookEntry(BaseModel):\n",
    "    source_node_id: str = Field(..., description=\"ID of the node this information came from\")\n",
    "    information: str = Field(..., description=\"Key information extracted from the node\")\n",
    "    relevance_score: float = Field(..., description=\"How relevant this information is (0-1)\")\n",
    "    information_type: str = Field(..., description=\"Type of information (causal, descriptive, statistical, etc.)\")\n",
    "\n",
    "class ExplorationDecision(BaseModel):\n",
    "    should_continue: bool = Field(..., description=\"Whether to continue exploring\")\n",
    "    reasoning: str = Field(..., description=\"Reasoning for the decision\")\n",
    "    next_nodes_to_explore: List[str] = Field(default=[], description=\"Specific node IDs to explore next\")\n",
    "    exploration_strategy: str = Field(..., description=\"How to explore next (neighbors, keywords, specific_nodes)\")\n",
    "    information_gaps: List[str] = Field(default=[], description=\"What information is still needed\")\n",
    "\n",
    "class FinalAnswer(BaseModel):\n",
    "    reasoning_steps: List[str] = Field(..., description=\"Step-by-step reasoning using gathered information\")\n",
    "    answer: str = Field(..., description=\"Final comprehensive answer to the question\")\n",
    "    confidence: float = Field(..., description=\"Confidence score (0-1) in the answer\")\n",
    "    sources: List[str] = Field(..., description=\"Node IDs used as sources for the answer\")\n",
    "    information_completeness: float = Field(..., description=\"How complete the gathered information is (0-1)\")\n",
    "\n",
    "answerString = \\\n",
    "\"\"\"\n",
    "class Reasoning_Step(BaseModel):\n",
    "    reasoning_step: str = Field(..., description=\"An intermediate reasoning step for breaking down the given context and query\")\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    reasoning: List[Reasoning_Step] = Field(..., description=\"List of reasoning steps\")\n",
    "    conclusion: bool = Field(..., description=\"The culminating final conclusion or answer to the question\")\n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55b269e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class IterativeKnowledgeGraphAgent:\n",
    "    def __init__(self, gml_file_path: str, vllm_client, tokenizer_name: str = \"Qwen/Qwen2.5-7B-Instruct-AWQ\", max_iterations: int = 5):\n",
    "        \"\"\"\n",
    "        Initialize the iterative Knowledge Graph QA agent\n",
    "        \n",
    "            tokenizer_name: Name of the tokenizer to use\n",
    "            max_iterations: Maximum number of exploration iterations\n",
    "        \"\"\"\n",
    "        self.graph = nx.read_gml(gml_file_path)\n",
    "        self.vllm_client = vllm_client\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "        self.max_iterations = max_iterations\n",
    "        \n",
    "        self.notebook: List[NotebookEntry] = []\n",
    "        self.explored_nodes: Set[str] = set()\n",
    "        self.current_iteration = 0\n",
    "        \n",
    "        self.entities = {}\n",
    "        self.documents = {}\n",
    "        # self.communities = {}\n",
    "        self._index_nodes()\n",
    "        self.query_embedding = None\n",
    "        self.community = self._build_community_index\n",
    "        # self.embedder = SentenceTransformer('all-MiniLM-L6-v2')  \n",
    "\n",
    "    \n",
    "    # def embed(self, text: str):\n",
    "    #     return self.embedder.encode(text)\n",
    "    \n",
    "    def _index_nodes(self):\n",
    "        \"\"\"Index nodes by their types for efficient retrieval\"\"\"\n",
    "        for node_id, node_data in self.graph.nodes(data=True):\n",
    "            labels = node_data.get('labels', [])\n",
    "            \n",
    "            if '__Entity__' in labels or 'Person' in labels:\n",
    "                self.entities[node_id] = node_data\n",
    "            elif 'Document' in labels:\n",
    "                self.documents[node_id] = node_data\n",
    "            # elif '__Community__' in labels:\n",
    "            #     self.communities[node_id] = node_data\n",
    "\n",
    "    def _build_community_index(self) -> Dict[str, List[str]]:\n",
    "        community_map = {}\n",
    "        for source, target, data in self.graph.edges(data=True):\n",
    "            if data.get(\"type\") == \"IN_COMMUNITY\":\n",
    "                community_map.setdefault(target, []).append(source)\n",
    "        return community_map\n",
    "    \n",
    "    def _create_prompt(self, system_message: str, user_message: str, schema: str) -> str:\n",
    "        \"\"\"Create a formatted prompt for the LLM\"\"\"\n",
    "        return self.tokenizer.apply_chat_template(\n",
    "            [\n",
    "                {\"role\": \"system\", \"content\": f\"{system_message}\\n\\nYou MUST adhere to this schema:\\n{schema}\"},\n",
    "                {\"role\": \"user\", \"content\": user_message},\n",
    "            ],\n",
    "            tokenize=False,\n",
    "            add_bos=True,\n",
    "            add_generation_prompt=True,\n",
    "        )\n",
    "    \n",
    "    def reset_agent_state(self):\n",
    "        \"\"\"Reset the agent's state for a new question\"\"\"\n",
    "        self.notebook = []\n",
    "        self.explored_nodes = set()\n",
    "        self.current_iteration = 0\n",
    "        # self.query_embedding = None\n",
    "\n",
    "    \n",
    "    def create_query_plan(self, question: str) -> QueryPlan:\n",
    "        \"\"\"Create a strategic plan for answering the given question\"\"\"\n",
    "        system_message = \"\"\"You are an expert knowledge graph exploration agent. Create a systematic plan \n",
    "        for answering questions using iterative graph exploration. Focus on what information you need to find \n",
    "        and how to search for it effectively.\"\"\"\n",
    "        \n",
    "        user_message = f\"\"\"\n",
    "        Question: {question}\n",
    "        \n",
    "        Create a detailed exploration plan for this question. The knowledge graph contains:\n",
    "        - Entities: Specific concepts, people, conditions, treatments, etc.\n",
    "        - Documents: Research papers and larger text chunks  \n",
    "        - Relationships: CAUSES, IS_ASSOCIATED_WITH, MENTIONS, IN_COMMUNITY\n",
    "        \n",
    "        Your plan should guide iterative exploration to gather comprehensive information.\n",
    "        \"\"\"\n",
    "        \n",
    "        schema = \"\"\"\n",
    "        class ReasoningStep(BaseModel):\n",
    "            step: str = Field(..., description=\"A reasoning step in the planning process\")\n",
    "            required_info: List[str] = Field(..., description=\"Types of information needed for this step\")\n",
    "\n",
    "        class QueryPlan(BaseModel):\n",
    "            reasoning_steps: List[ReasoningStep] = Field(..., description=\"Step-by-step plan to answer the query\")\n",
    "            key_concepts: List[str] = Field(..., description=\"Key concepts that need to be found in the knowledge graph\")\n",
    "            search_strategy: str = Field(..., description=\"Strategy for searching the knowledge graph\")\n",
    "            expected_answer_type: str = Field(..., description=\"What type of answer is expected (causal, descriptive, comparative, etc.)\")\n",
    "        \"\"\"\n",
    "        \n",
    "        prompt = self._create_prompt(system_message, user_message, schema)\n",
    "        \n",
    "        original_schema = self.vllm_client.schema\n",
    "        self.vllm_client.schema = QueryPlan\n",
    "        \n",
    "        result = self.vllm_client(prompt, sampling_params={\n",
    "            \"n\": 1, \"min_tokens\": 100, \"max_tokens\": 800, \"temperature\": 0.1\n",
    "        })\n",
    "        \n",
    "        self.vllm_client.schema = original_schema\n",
    "        return result\n",
    "    \n",
    "    def find_initial_nodes(self, plan: QueryPlan, top_k: int = 10) -> List[str]:\n",
    "        \"\"\"Find initial nodes to start exploration based on the query plan\"\"\"\n",
    "        keywords = plan.key_concepts.copy()\n",
    "        for step in plan.reasoning_steps:\n",
    "            keywords.extend(step.required_info)\n",
    "        \n",
    "        relevant_nodes = []\n",
    "        keywords_lower = [kw.lower() for kw in keywords]\n",
    "        # if self.query_embedding is None:\n",
    "        #     query_text = \" \".join(plan.key_concepts + sum((step.required_info for step in plan.reasoning_steps), []))\n",
    "        #     self.query_embedding = np.array(self.embed(query_text)).reshape(1, -1)\n",
    "        \n",
    "        for node_id, node_data in self.graph.nodes(data=True):\n",
    "            score = 0\n",
    "            searchable_text = \"\"\n",
    "            \n",
    "            for field in ['description', 'text', 'summary', 'full_content']:\n",
    "                if field in node_data:\n",
    "                    searchable_text += \" \" + str(node_data[field])\n",
    "            searchable_text = searchable_text.lower()\n",
    "            \n",
    "            for keyword in keywords_lower:\n",
    "                if keyword in searchable_text:\n",
    "                    score += searchable_text.count(keyword)\n",
    "\n",
    "            # # add cosine similarity if embeddings are available\n",
    "            # if 'embedding' in node_data:\n",
    "            #     embedding = np.array(node_data['embedding']).reshape(1, -1)\n",
    "            #     sim = cosine_similarity(self.query_embedding, embedding)[0][0]\n",
    "            #     score += sim * 5\n",
    "            \n",
    "            if score > 0:\n",
    "                relevant_nodes.append((node_id, score))\n",
    "        \n",
    "        relevant_nodes.sort(key=lambda x: x[1], reverse=True)\n",
    "        return [node_id for node_id, _ in relevant_nodes[:top_k]]\n",
    "    \n",
    "    def extract_information_from_node(self, node_id: str, question: str, plan: QueryPlan) -> Optional[NotebookEntry]:\n",
    "        \"\"\"Extract relevant information from a specific node\"\"\"\n",
    "        if node_id not in self.graph:\n",
    "            return None\n",
    "        \n",
    "        node_data = self.graph.nodes[node_id]\n",
    "        \n",
    "        node_info = f\"Node ID: {node_id}\\n\"\n",
    "        node_info += f\"Labels: {node_data.get('labels', [])}\\n\"\n",
    "        \n",
    "        if 'description' in node_data:\n",
    "            node_info += f\"Description: {node_data['description']}\\n\"\n",
    "        if 'text' in node_data:\n",
    "            node_info += f\"Text: {node_data['text'][:1000]}{'...' if len(str(node_data['text'])) > 1000 else ''}\\n\"\n",
    "        if 'summary' in node_data:\n",
    "            node_info += f\"Summary: {node_data['summary']}\\n\"\n",
    "        if 'full_content' in node_data:\n",
    "            node_info += f\"Full Content: {str(node_data['full_content'])[:500]}{'...' if len(str(node_data.get('full_content', ''))) > 500 else ''}\\n\"\n",
    "        \n",
    "        \n",
    "        neighbors = list(self.graph.neighbors(node_id))\n",
    "        if neighbors:\n",
    "            node_info += f\"Connected to {len(neighbors)} other nodes\\n\"\n",
    "        \n",
    "        system_message = \"\"\"You are an expert information extractor. Extract the most relevant and useful \n",
    "        information from the given node that helps answer the question. Focus on key facts, relationships, \n",
    "        and insights.\"\"\"\n",
    "        \n",
    "        user_message = f\"\"\"\n",
    "        Question: {question}\n",
    "        Query Plan: {plan.model_dump_json(indent=2)}\n",
    "        \n",
    "        Node Information:\n",
    "        {node_info}\n",
    "        \n",
    "        Extract the most relevant information from this node. Determine its relevance score and information type.\n",
    "        \"\"\"\n",
    "        \n",
    "        schema = \"\"\"\n",
    "        class NotebookEntry(BaseModel):\n",
    "            source_node_id: str = Field(..., description=\"ID of the node this information came from\")\n",
    "            information: str = Field(..., description=\"Key information extracted from the node\")\n",
    "            relevance_score: float = Field(..., description=\"How relevant this information is (0-1)\")\n",
    "            information_type: str = Field(..., description=\"Type of information (causal, descriptive, statistical, etc.)\")\n",
    "        \"\"\"\n",
    "        \n",
    "        prompt = self._create_prompt(system_message, user_message, schema)\n",
    "        \n",
    "        original_schema = self.vllm_client.schema\n",
    "        self.vllm_client.schema = NotebookEntry\n",
    "        \n",
    "        try:\n",
    "            result = self.vllm_client(prompt, sampling_params={\n",
    "                \"n\": 1, \"min_tokens\": 50, \"max_tokens\": 400, \"temperature\": 0.1\n",
    "            })\n",
    "            self.vllm_client.schema = original_schema\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting from node {node_id}: {e}\")\n",
    "            self.vllm_client.schema = original_schema\n",
    "            return None\n",
    "    \n",
    "    def decide_next_exploration(self, question: str, plan: QueryPlan) -> ExplorationDecision:\n",
    "        \"\"\"Decide whether to continue exploring and what to explore next\"\"\"\n",
    "        \n",
    "        notebook_summary = \"\\n\".join([\n",
    "            f\"- {entry.information} (relevance: {entry.relevance_score:.2f}, type: {entry.information_type})\"\n",
    "            for entry in self.notebook\n",
    "        ])\n",
    "        \n",
    "        system_message = \"\"\"You are an expert research agent. Based on the information gathered so far, \n",
    "        decide whether you have enough information to answer the question or if you need to explore more. \n",
    "        If exploring more, specify what nodes or areas to focus on next.\"\"\"\n",
    "        \n",
    "        user_message = f\"\"\"\n",
    "        Question: {question}\n",
    "        Query Plan: {plan.model_dump_json(indent=2)}\n",
    "        Current Iteration: {self.current_iteration + 1}/{self.max_iterations}\n",
    "        \n",
    "        Information Gathered So Far:\n",
    "        {notebook_summary if notebook_summary else \"No information gathered yet\"}\n",
    "        \n",
    "        Explored Nodes: {list(self.explored_nodes)}\n",
    "        \n",
    "        Should you continue exploring? If yes, what should you explore next?\n",
    "        \"\"\"\n",
    "        \n",
    "        schema = \"\"\"\n",
    "        class ExplorationDecision(BaseModel):\n",
    "            should_continue: bool = Field(..., description=\"Whether to continue exploring\")\n",
    "            reasoning: str = Field(..., description=\"Reasoning for the decision\")\n",
    "            next_nodes_to_explore: List[str] = Field(default=[], description=\"Specific node IDs to explore next\")\n",
    "            exploration_strategy: str = Field(..., description=\"How to explore next (neighbors, keywords, specific_nodes)\")\n",
    "            information_gaps: List[str] = Field(default=[], description=\"What information is still needed\")\n",
    "        \"\"\"\n",
    "        \n",
    "        prompt = self._create_prompt(system_message, user_message, schema)\n",
    "        \n",
    "        original_schema = self.vllm_client.schema\n",
    "        self.vllm_client.schema = ExplorationDecision\n",
    "        \n",
    "        result = self.vllm_client(prompt, sampling_params={\n",
    "            \"n\": 1, \"min_tokens\": 100, \"max_tokens\": 600, \"temperature\": 0.2\n",
    "        })\n",
    "        \n",
    "        self.vllm_client.schema = original_schema\n",
    "        return result\n",
    "    \n",
    "    #edges arent directional right?\n",
    "    def get_neighbor_nodes(self, node_ids: List[str], max_neighbors: int = 15) -> List[str]:\n",
    "        \"\"\"Get neighboring nodes for further exploration\"\"\"\n",
    "        neighbors = set()\n",
    "        \n",
    "        for node_id in node_ids:\n",
    "            if node_id in self.graph:\n",
    "                node_neighbors = list(self.graph.neighbors(node_id))\n",
    "                neighbors.update(node_neighbors)\n",
    "        neighbors -= self.explored_nodes        \n",
    "        return list(neighbors)[:max_neighbors]\n",
    "    \n",
    "    def generate_final_answer(self, question: str, plan: QueryPlan) -> FinalAnswer:\n",
    "        \"\"\"Generate the final answer using all gathered information\"\"\"\n",
    "        \n",
    "        sorted_entries = sorted(self.notebook, key=lambda x: x.relevance_score, reverse=True)\n",
    "        \n",
    "        notebook_content = \"\"\n",
    "        for i, entry in enumerate(sorted_entries, 1):\n",
    "            notebook_content += f\"{i}. Source: Node {entry.source_node_id}\\n\"\n",
    "            notebook_content += f\"   Information: {entry.information}\\n\"\n",
    "            notebook_content += f\"   Type: {entry.information_type}, Relevance: {entry.relevance_score:.2f}\\n\\n\"\n",
    "        \n",
    "        system_message = \"\"\"You are an expert researcher synthesizing information to provide a comprehensive answer. \n",
    "        Use all the gathered information from your notebook to construct a well-reasoned, complete response.\"\"\"\n",
    "        \n",
    "        user_message = f\"\"\"\n",
    "        Question: {question}\n",
    "        Query Plan: {plan.model_dump_json(indent=2)}\n",
    "        \n",
    "        Information from Knowledge Graph Exploration:\n",
    "        {notebook_content}\n",
    "        \n",
    "        Total iterations completed: {self.current_iteration}\n",
    "        Total nodes explored: {len(self.explored_nodes)}\n",
    "        \n",
    "        Provide a comprehensive answer with clear reasoning steps, confidence assessment, and completeness evaluation.\n",
    "        \"\"\"\n",
    "        \n",
    "        schema = \"\"\"\n",
    "        class FinalAnswer(BaseModel):\n",
    "            reasoning_steps: List[str] = Field(..., description=\"Step-by-step reasoning using gathered information\")\n",
    "            answer: str = Field(..., description=\"Final comprehensive answer to the question\")\n",
    "            confidence: float = Field(..., description=\"Confidence score (0-1) in the answer\")\n",
    "            sources: List[str] = Field(..., description=\"Node IDs used as sources for the answer\")\n",
    "            information_completeness: float = Field(..., description=\"How complete the gathered information is (0-1)\")\n",
    "        \"\"\"\n",
    "        \n",
    "        prompt = self._create_prompt(system_message, user_message, schema)\n",
    "        \n",
    "        original_schema = self.vllm_client.schema\n",
    "        self.vllm_client.schema = FinalAnswer\n",
    "        \n",
    "        result = self.vllm_client(prompt, sampling_params={\n",
    "            \"n\": 1, \"min_tokens\": 300, \"max_tokens\": 2000, \"temperature\": 0.1\n",
    "        })\n",
    "        \n",
    "        self.vllm_client.schema = original_schema\n",
    "        return result\n",
    "    \n",
    "    def answer_question(self, question: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Complete iterative pipeline to answer a question using the knowledge graph\n",
    "        \"\"\"\n",
    "        print(f\"Starting iterative exploration for: {question}\")\n",
    "        \n",
    "        self.reset_agent_state()\n",
    "        \n",
    "        # Step 1: Create query plan\n",
    "        print(\"Creating query plan...\")\n",
    "        plan = self.create_query_plan(question)\n",
    "        print(f\"Plan created with {len(plan.reasoning_steps)} steps\")\n",
    "        \n",
    "        # Step 2: Find initial nodes\n",
    "        print(\"  Finding initial nodes...\")\n",
    "        initial_nodes = self.find_initial_nodes(plan, top_k=8)\n",
    "        print(f\"   Found {len(initial_nodes)} initial nodes to explore\")\n",
    "        \n",
    "        exploration_log = []\n",
    "        \n",
    "        # Step 3: Iterative exploration\n",
    "        while self.current_iteration < self.max_iterations:\n",
    "            print(f\"\\nIteration {self.current_iteration + 1}/{self.max_iterations}\")\n",
    "            \n",
    "            # Determine nodes to explore this iteration\n",
    "            if self.current_iteration == 0:\n",
    "                nodes_to_explore = initial_nodes\n",
    "            else:\n",
    "                # Make exploration decision\n",
    "                decision = self.decide_next_exploration(question, plan)\n",
    "                exploration_log.append(decision)\n",
    "                \n",
    "                if not decision.should_continue:\n",
    "                    print(f\"Agent decided to stop: {decision.reasoning}\")\n",
    "                    break\n",
    "                \n",
    "                if decision.next_nodes_to_explore:\n",
    "                    nodes_to_explore = decision.next_nodes_to_explore\n",
    "                elif decision.exploration_strategy == \"neighbors\":\n",
    "                    # Explore neighbors of high-relevance nodes\n",
    "                    high_relevance_nodes = [entry.source_node_id for entry in self.notebook \n",
    "                                          if entry.relevance_score > 0.7]\n",
    "                    nodes_to_explore = self.get_neighbor_nodes(high_relevance_nodes or [entry.source_node_id for entry in self.notebook[-3:]])\n",
    "                else:\n",
    "                    # Find new nodes based on information gaps\n",
    "                    nodes_to_explore = self.find_initial_nodes(plan, top_k=5)\n",
    "            \n",
    "            nodes_to_explore = [n for n in nodes_to_explore if n not in self.explored_nodes]\n",
    "            \n",
    "            if not nodes_to_explore:\n",
    "                print(\"No new nodes to explore\")\n",
    "                break\n",
    "            \n",
    "            print(f\"Exploring {len(nodes_to_explore)} nodes...\")\n",
    "            \n",
    "            # Extract information from nodes\n",
    "            for node_id in nodes_to_explore[:5]:  # Limit to 5 nodes per iter\n",
    "                if node_id not in self.explored_nodes:\n",
    "                    entry = self.extract_information_from_node(node_id, question, plan)\n",
    "                    if entry and entry.relevance_score > 0.3: \n",
    "                        self.notebook.append(entry)\n",
    "                        print(f\"     Added info from node {node_id} (relevance: {entry.relevance_score:.2f})\")\n",
    "                    \n",
    "                    self.explored_nodes.add(node_id)\n",
    "            \n",
    "            self.current_iteration += 1\n",
    "        \n",
    "        print(\"\\n Generating final answer...\")\n",
    "        final_answer = self.generate_final_answer(question, plan)\n",
    "        \n",
    "        print(f\" Exploration Summary:\")\n",
    "        print(f\"   - Total iterations: {self.current_iteration}\")\n",
    "        print(f\"   - Nodes explored: {len(self.explored_nodes)}\")\n",
    "        print(f\"   - Information gathered: {len(self.notebook)} entries\")\n",
    "        print(f\"   - Final confidence: {final_answer.confidence:.2f}\")\n",
    "        \n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"plan\": plan,\n",
    "            \"exploration_log\": exploration_log,\n",
    "            \"notebook\": self.notebook,\n",
    "            \"explored_nodes\": list(self.explored_nodes),\n",
    "            \"iterations_completed\": self.current_iteration,\n",
    "            \"final_answer\": final_answer\n",
    "        }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec7a975",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23cadda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.graphs.graph_document import GraphDocument\n",
    "from langchain_core.documents import Document\n",
    "from retry import retry\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "from prompts import *\n",
    "from vllm_client import VLLMClient\n",
    "\n",
    "# llm_transformer = llm.LLMGraphTransformer(\n",
    "#     model=None,\n",
    "#     prompt=ontology_prompt, # declared up top\n",
    "#     allowed_relationships=[\"CAUSES\", \"IS_ASSOCIATED_WITH\"],\n",
    "#     node_properties=[\"description\"],\n",
    "#     relationship_properties=[\"description\"]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22c7ebb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = VLLMClient(schema=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d01e7399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iterative exploration for: What is the causal relationship between insomnia and chronic pain?\n",
      "Creating query plan...\n",
      "Plan created with 4 steps\n",
      "  Finding initial nodes...\n",
      "   Found 8 initial nodes to explore\n",
      "\n",
      "Iteration 1/5\n",
      "Exploring 8 nodes...\n",
      "     Added info from node 93 (relevance: 0.85)\n",
      "     Added info from node 335 (relevance: 0.85)\n",
      "     Added info from node 336 (relevance: 0.85)\n",
      "     Added info from node 337 (relevance: 0.85)\n",
      "     Added info from node 338 (relevance: 0.85)\n",
      "\n",
      "Iteration 2/5\n",
      "Exploring 3 nodes...\n",
      "\n",
      "Iteration 3/5\n",
      "No new nodes to explore\n",
      "\n",
      " Generating final answer...\n",
      " Exploration Summary:\n",
      "   - Total iterations: 2\n",
      "   - Nodes explored: 8\n",
      "   - Information gathered: 5 entries\n",
      "   - Final confidence: 0.85\n",
      "=== FINAL ANSWER ===\n",
      "The causal relationship between insomnia and chronic pain is well-established through multiple research studies and clinical trials. Insomnia is a significant risk factor for various pain conditions, including back pain, headaches, and stomach pain. Chronic pain, in turn, can exacerbate insomnia, creating a bidirectional relationship. Genetic susceptibility plays a role in this relationship, as insomnia increases the genetic predisposition to back pain, and vice versa. Psychological factors such as depression and anxiety are also strongly associated with both insomnia and chronic pain, further complicating the relationship. Psychological interventions can help alleviate severe pain and improve mental health, suggesting a potential therapeutic approach to managing both conditions.\n",
      "Confidence: 0.85\n",
      "\n",
      "=== EXPLORATION NOTEBOOK ===\n",
      "Node 93: Insomnia (sleeplessness) is significantly associated with the risk of various pain conditions such as neck and shoulder pain, back pain, headaches, and stomach and abdominal pain. Additionally, insomnia increases the genetic susceptibility of back pain, and back pain is associated with an increased risk of insomnia. Depression and anxiety are also associated with insomnia and various pain conditions, creating a bidirectional relationship. Some studies have found a causal relationship between headaches and anxiety, and psychological interventions can help alleviate severe pain and improve mental health. (score: 0.85)\n",
      "Node 335: The study reveals a significant association between insomnia and various pain conditions, including head pain, hip pain, and multisite pain. Insomnia is causally related to the genetic susceptibility of these pain conditions. Knee pain is also associated with insomnia, with a mutual predisposing relationship. Localized pain, excluding widespread pain, may be a mutual predisposing factor with insomnia. The study uses GWAS data from 23andMe, the Psychiatric Genomics Consortium, and the UK Biobank, which also provides depression data. The findings align with previous MR analysis confirming that multisite pain is associated with insomnia, and depressive disorders are closely linked with psychological disorders and also associated with insomnia. (score: 0.85)\n",
      "Node 336: The study reveals a significant association between insomnia and various pain conditions, including head pain, hip pain, and multisite pain. Insomnia is causally related to the genetic susceptibility of these pain conditions. Knee pain is also associated with insomnia, with a mutual predisposing relationship. Localized pain, excluding widespread pain, may be a mutual predisposing factor with insomnia. The study uses GWAS data sources and aligns with previous MR analysis confirming the association between multisite pain and insomnia, and depressive disorders with insomnia. (score: 0.85)\n",
      "Node 337: Insomnia (sleeplessness) is a significant risk factor for various pain conditions, including back pain, stomach and abdominal pain, facial pain, and headache. It also causes a reduced predisposition of being pain-free. Additionally, depression is strongly associated with an increased risk of all these pain conditions and causes a reduced predisposition of being pain-free. Psychological interventions can help alleviate severe pain, improve mental health, and potentially serve as an alternative to medication analgesia in some cases. (score: 0.85)\n",
      "Node 338: Insomnia (sleeplessness) is a significant risk factor for various pain conditions, including back pain, stomach and abdominal pain, facial pain, and headaches. It also causes a reduced predisposition of being pain-free. The bidirectional relationships between pain conditions and mental health disorders, particularly depression and anxiety, are highlighted. Psychological interventions can help alleviate severe pain and improve mental health. (score: 0.85)\n"
     ]
    }
   ],
   "source": [
    "agent = IterativeKnowledgeGraphAgent(\n",
    "    gml_file_path=\"graph_dump.gml\",\n",
    "    vllm_client=client,\n",
    "    max_iterations=5\n",
    ")\n",
    "\n",
    "question = \"What is the causal relationship between insomnia and chronic pain?\"\n",
    "result = agent.answer_question(question)\n",
    "\n",
    "print(\"=== FINAL ANSWER ===\")\n",
    "print(result[\"final_answer\"].answer)\n",
    "print(f\"Confidence: {result['final_answer'].confidence}\")\n",
    "\n",
    "print(\"\\n=== EXPLORATION NOTEBOOK ===\")\n",
    "for entry in result[\"notebook\"]:\n",
    "    print(f\"Node {entry.source_node_id}: {entry.information} (score: {entry.relevance_score})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
